# 深度神经网络

> 其实所有CNN，RNN，LSTM等神经网络都是MLP多层感知机的变种。

> MLP可以拟合非线性函数，因此理论上，MLP可以拟合任意的函数。

> 然而实际上，当输入数据过多时，全连接层的会产生很多的参数，训练起来非常困难。
>
> 因此，为了更好的拟合数据，得到效果更优、训练更快的模型，将会通过输入数据类内部的一些显而易见的或者说是启发式的规则来改变多层感知机的结构。

# 卷积*

### 从全连接到卷积*

> 若是对图像数据采用MLP来进行训练，将会产生大量参数，为了简化模型容量（参数数量），采用如下两个原则。
>
> 平移不变性使得模型在训练过程中一个图片中相同的图像块的输入，可以输出相同的结果，因此可以采用共享参数，来大大地减少模型的复杂度（共享参数，减少参数数量）。
>
> 局部性表达了下一层输入应该只与上一层输出的一部分相邻图像点相关，因此删掉了来自大量不相邻的图像点的影响，同时也可以大大地减少模型的复杂度（减少参数数量）。

- 平移不变性
- 局部性

#### 图像的全连接

- 将输入和输出变形为矩阵（宽度，高度）

- 将权重变形为4-D张量（h，w）到（h_hat，w_hat）

    - 权重一般是两个张量的映射关系，所以![image-20211123133250231](.\typora-user-images\image-20211123133250231.png)表达的是![image-20211123133304950](.\typora-user-images\image-20211123133304950.png)到![image-20211123133327156](.\typora-user-images\image-20211123133327156.png)的映射关系。

    ![image-20211123133100806](.\typora-user-images\image-20211123133100806.png)

- V 是 W 的重新索引

    - 由于其中下标变量过多，因此对 W 进行重新索引。
    - 令 k =  i + a，l = j + b，其中 a, b 为变量，求和中并没有用到 i 和 j ，所以可以等价。

#### 平移不变性规则

- V 不应该依赖于（i，j）
    - 当 i，j 变化时，代表输入的位置和输出的位置发生了变化，然而这个变化不应该对相同的输入产生影响，所以权重 V 的值不应该受到 i，j 的影响。
- 解决方案：![image-20211123134433096](.\typora-user-images\image-20211123134433096.png)
- ![image-20211123134447319](.\typora-user-images\image-20211123134447319.png)
- 对于下一层的输入h（i，j），它的值是上一层图像从X（i，j）位置出发，所有其他位置的加权和。
- 这就是深度学习中的2维卷积（实际上是2维交叉相关）。

#### 局部性规则

![image-20211123140354800](.\typora-user-images\image-20211123140354800.png)

- 当评估 h（i，j）时，不应该用远离 X（i，j）的参数。
- 解决方案：当|a|，|b| > Δ 时，使得 V（a，b）= 0

![image-20211123140608608](.\typora-user-images\image-20211123140608608.png)

### 卷积的填充

- 在输入的周围添加额外的行/列

![image-20211123211601719](.\typora-user-images\image-20211123211601719.png)

![image-20211123212141525](.\typora-user-images\image-20211123212141525.png)

- 填充![image-20211123211651493](.\typora-user-images\image-20211123211651493.png)行和![image-20211123211703669](.\typora-user-images\image-20211123211703669.png)列，输出形状为

    ![image-20211123211943242](.\typora-user-images\image-20211123211943242.png)

- 通常取![image-20211123211736216](.\typora-user-images\image-20211123211736216.png)，![image-20211123211749994](.\typora-user-images\image-20211123211749994.png)

    - 当![image-20211123211805567](.\typora-user-images\image-20211123211805567.png)为奇数：在上下两侧填充![image-20211123211930991](.\typora-user-images\image-20211123211930991.png)。
    - 当![image-20211123211826841](.\typora-user-images\image-20211123211826841.png)为偶数：在上侧填充![image-20211123211855906](.\typora-user-images\image-20211123211855906.png)，在下侧填充![image-20211123211903267](.\typora-user-images\image-20211123211903267.png)。

### 卷积的步幅

- 步幅是指行/列的滑动步长。
    - 例：高度3，宽度2 的步幅。

![image-20211123212110555](.\typora-user-images\image-20211123212110555.png)

![image-20211123212157734](.\typora-user-images\image-20211123212157734.png)

- 给定高度![image-20211123212311032](.\typora-user-images\image-20211123212311032.png)和宽度![image-20211123212319435](.\typora-user-images\image-20211123212319435.png)的步幅，输出形状是

    ![image-20211123212332515](.\typora-user-images\image-20211123212332515.png)

- 如果![image-20211123212345694](.\typora-user-images\image-20211123212345694.png)，![image-20211123212355349](.\typora-user-images\image-20211123212355349.png)

- 如果输入高度和宽度可以被步幅整除，并往下取整。

![image-20211123212404867](.\typora-user-images\image-20211123212404867.png)

### 多个输入输出通道

> 彩色图像可能有RGB三个通道，所以转换为灰度会丢失信息。
>
> 每个输出通道可以识别特定模式。
>
> 输入通道核识别并组合输入中的模式。
>
> 总结：其实每个输入的一个通道都有对应的一个二维卷积核，将这些通道的卷积核堆积起来就是三维的卷积核，也就是单个输出通道的三维卷积核。所以要是我们想要有多个输出通道，那我们就需要有多个三维卷积核，来生成多个通道结果。

#### 多个输入通道

- 每个通道都有一个卷积核，结果是所有通道卷积结果的和。

![image-20211124180021570](.\typora-user-images\image-20211124180021570.png)

![image-20211124180030491](.\typora-user-images\image-20211124180030491.png)

- 输入![image-20211124180121239](.\typora-user-images\image-20211124180121239.png)
- 核![image-20211124180203278](.\typora-user-images\image-20211124180203278.png)
- 输出![image-20211124180139707](.\typora-user-images\image-20211124180139707.png)

![image-20211124180221096](.\typora-user-images\image-20211124180221096.png)

#### 多个输出通道

- 无论有多少输入通道，到目前为止我们只用到单输出通道。
- 我们可以有多个三维卷积核，每个核生成一个输出通道。
- 输入![image-20211124180356407](.\typora-user-images\image-20211124180356407.png)
- 核![image-20211124180423004](.\typora-user-images\image-20211124180423004.png)
- 输出![image-20211124180631355](.\typora-user-images\image-20211124180631355.png)

![image-20211124180639861](.\typora-user-images\image-20211124180639861.png)

#### 1 X 1 卷积层

> ![image-20211124180941595](.\typora-user-images\image-20211124180941595.png)是一个受欢迎的选择。它不识别空间模式，只是融合通道。

![image-20211124181019019](.\typora-user-images\image-20211124181019019.png)

- 相当于输入形状为![image-20211124181043841](.\typora-user-images\image-20211124181043841.png)，权重为![image-20211124181102369](.\typora-user-images\image-20211124181102369.png)的全连接层。

#### 二维卷积层

- 输入 ![image-20211124181447972](.\typora-user-images\image-20211124181447972.png)
- 核![image-20211124181458512](.\typora-user-images\image-20211124181458512.png)
- 偏差![image-20211124181505402](.\typora-user-images\image-20211124181505402.png)
- 输出![image-20211124181511878](.\typora-user-images\image-20211124181511878.png)

![image-20211124181612022](.\typora-user-images\image-20211124181612022.png)

- 计算复杂度（浮点计算数 FLOP） ![image-20211124181522097](.\typora-user-images\image-20211124181522097.png)

![image-20211124181544525](.\typora-user-images\image-20211124181544525.png)

- 10层，1M样本，10PFlops
- （CPU：0.15 TF = 18h，GPU：12 TF = 14min）

### 池化

- 卷积对位置敏感。
    - 检测垂直边缘。

![image-20211124085036331](.\typora-user-images\image-20211124085036331.png)

- 需要一定程度的平移不变性。
    - 照明，物体位置，比例，外观等等因图像而异。

#### 二维最大池化

- 返回窗口中的最大值。

![image-20211124085203603](.\typora-user-images\image-20211124085203603.png)

![image-20211124085211950](.\typora-user-images\image-20211124085211950.png)

- 返回滑动窗口中的最大值（最后应该是只有前两列的 1）。

![image-20211124085258119](.\typora-user-images\image-20211124085258119.png)

#### 填充，步幅和多个通道

- 池化层与卷积层类似，都具有填充和步幅。
- 没有可学习的参数。
- 在每个输入通道应用池化层以获得相应的输出通道。
- 输出通道数 = 输入通道数。

#### 平均池化层

- 最大池化层：每个窗口中最强的模式信号。
- 平均池化层：将最大池化层中的 “最大” 操作替换为 “平均” 操作。

# LeNet

> 手写数字识别
>
> 早期成功的神经网络。
>
> 先使用卷积层来学习图片空间信息，然后使用全连接层来转换到类别空间。

![image-20211124090447808](.\typora-user-images\image-20211124090447808.png)

# AlexNet

> 卷起了神经网络的热潮

- AlexNet对比LeNet

![image-20211125090137682](.\typora-user-images\image-20211125090137682.png)

- AlexNet赢了2012年ImageNet竞赛。
- 更深更大的LeNet
- 主要改进：
    - 丢弃法
    - ReLU
    - MaxPooling
    - 数据增强

![image-20211125090527733](.\typora-user-images\image-20211125090527733.png)

- 计算机视觉方法论的改变

![image-20211125090343909](.\typora-user-images\image-20211125090343909.png)

- AlexNet架构

![image-20211125090413969](.\typora-user-images\image-20211125090413969.png)

![image-20211125090433818](.\typora-user-images\image-20211125090433818.png)

![image-20211125090445313](.\typora-user-images\image-20211125090445313.png)

- 复杂度

![image-20211125090603260](.\typora-user-images\image-20211125090603260.png)

# VGG

> VGG就是更大更深的AlexNet（重复的VGG块），看起来也更优雅一些。
>
> VGG也发现了多个叠加的 3 X 3 的卷积，比少数 5 X 5 卷积效果更好。

![image-20211125091452338](.\typora-user-images\image-20211125091452338.png)

![image-20211125091538782](.\typora-user-images\image-20211125091538782.png)

- 多个VGG块后接全连接层。
- 不同次数的重复块得到不同的架构。

![image-20211125091553928](.\typora-user-images\image-20211125091553928.png)

# 批量归一化

> 将每层的输入数据的分布都尽可能地靠近原始数据的分布，并学习其特征分布。

- 损失出现在最后，后面的层训练较快
- 数据在最底层，底层的训练慢，底层一变化，所有都得跟着变，后面的层需要重新训练多次，导致收敛变慢
- 固定小批量里面的均值和方差。

![image-20211125163528421](.\typora-user-images\image-20211125163528421.png)

- 然后再做额外的调整（可学习的参数）

![image-20211125163547144](.\typora-user-images\image-20211125163547144.png)

- 可学习的参数为![image-20211125163851904](.\typora-user-images\image-20211125163851904.png)和![image-20211125163901678](.\typora-user-images\image-20211125163901678.png)
- 作用在
    - 全连接层和卷积层输出上，激活函数前
    - 全连接层和卷积层输入上
- 对全连接层，作用在特征维。
- 对于卷积层，作用在通道维。

- 最初论文是想用来减少内部协变量转移（实际并没有变化）
- 后续有论文指出可能是通过在每个小批量里加入噪音来控制模型复杂度。

![image-20211125164509603](.\typora-user-images\image-20211125164509603.png)

- 因此没必要跟丢弃法混合使用

- 可以加速收敛速度，但一般不改变模型精度。

# 残差网络（ResNet）

> 残差块使得很深的网络更加容易训练
>
> 残差网络对随后的深度神经网络设计产生了深远的影响。
>
> 其实残差网络使得每次对神经网络进行更复杂的设计时，网络输出的值域不会偏离最优点。

- 加入更多的层不一定能改进精度。

![image-20211125182200504](.\typora-user-images\image-20211125182200504.png)

![image-20211125182309644](.\typora-user-images\image-20211125182309644.png)

### 残差块

- 串联一个层来改变函数类，我们希望能扩大函数类
- 残差块加入快速通道（右边）来得到![image-20211125182955177](.\typora-user-images\image-20211125182955177.png)的结构

![image-20211125183015568](.\typora-user-images\image-20211125183015568.png)

### ResNet块

- 高宽减半ResNet（步幅 2）
- 后接多个高宽不变ResNet块
    - 第一个ResNet块的输入输出不变
    - 第二个ResNet块第一个卷积层步幅为 2，并增添通道数，所以在块外也需要借一个1X1卷积。

![image-20211125183157090](.\typora-user-images\image-20211125183157090.png)

### 残差的概念

![image-20211125192308927](.\typora-user-images\image-20211125192308927.png)

# 数据增广

> 一般是会对应用领域的变化来进行一些特定的数据增强。

- 增加一个已有数据集，使得有更多的多样性
    - 在语言里面加入各种不同的背景噪音。
    - 改变图片的颜色和形状。

### 翻转

- 左右翻转
- 上下翻转
    - 不总是可行

### 切割

- 从图片中切出一块，然后变形到固定形状。
    - 随机高宽比， 大小，位置。

### 颜色

- 改变色调，饱和度，明亮度。

### 几十种其他的办法

https://github.com/aleju/imgaug

# 迁移学习

> 目前深度学习领域中特别重要的一项。

> 标注一个数据集很贵（都是人工标注）。
>
> 迁移学习通过在大数据上得到的预训练好的模型来初始化模型权重来完成提升精度。
>
> 预训练模型质量很重要。
>
> 迁移学习通常速度更快，精度更高。

### 网络架构

- 一个神经网络一般可以分成两块
    - 特征抽取将原始像素变成容易线性分割的特征。
    - 线性分类器来做分类。

### 微调

- 对于相同类型的数据，不同的结果标号，并不用重新进行训练。

![image-20211127093855564](.\typora-user-images\image-20211127093855564.png)

### 训练

- 是一个目标数据集上的正常训练任务，但使用更强的正则化。
    - 使用更小的学习率
    - 使用更少的数据迭代
- 原数据集远复杂于目标数据，通常微调效果更好。

### 重用分类器权重

- 源数据集可能也有目标数据中的部分标号。
- 可以使用预训练好的模型分类器中对应标号对应的向量来做初始化。

### 固定一些层

- 神经网络通常学习有层次的特征表示
    - 低层次的特征更加通用
    - 高层次的特征则更跟数据集相关
- 可以固定底部一些层的参数，不参与更新
    - 更强的正则。

# 目标检测

> 物体检测识别图片里的多个物体的类别和位置，位置通常用边缘框表示。

> 一类目标检测算法基于锚框来预测
>
> 首先生成大量锚框，并赋予标号，每个锚框作为一个样本进行训练
>
> 在预测时，使用 NMS 来去掉冗余的预测

### 目标检测数据集

- 每行表示一个物体
    - 图片文件名，物体类别，边缘框
- COCO（ cocodataset.org ）
    - 80 物体， 330k 图片， 1.5M 物体

### 锚框

- 一类目标检测算法是基于锚框
    - 提出多个被称为锚框的区域（边缘框）
    - 预测每个锚框里是否含有关注的物体
    - 如果是，预测从这个锚框到真实边缘框的偏移

![image-20211129164606108](.\typora-user-images\image-20211129164606108.png)

### 交并比（ IoU ）

![image-20211129164858357](.\typora-user-images\image-20211129164858357.png)

- IoU 用来计算两个框之间的相似度
    - 0表示无重叠， 1表示重合
- 这是 Jacquard 指数的一个特殊情况
    - 给定两个集合 A 和 B

![image-20211129164827695](.\typora-user-images\image-20211129164827695.png)

### 赋予锚框标号

- 每个锚框是一个训练样本
- 将每个锚框，要么标注成北京，要么关联上一个真实边缘框
- 我们可能会生成大量的锚框
    - 这个导致大量的负类样本

![image-20211129165528969](.\typora-user-images\image-20211129165528969.png)

### 使用非极大值抑制（ NMS ）输出

- 每个锚框预测一个边缘框
- NMS 可以合并相似的预测。
    - 选中是非背景类的最大预测值。
    - 去掉所有其他和它 IoU 值大于 θ 的预测。
    - 重复上述过程直到所有预测要么被选中， 要么被去掉。
